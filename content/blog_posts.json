[
  {
    "date": "",
    "data-tags": "code",
    "image": "images/placeholder/pic02.jpg",
    "title": "Unconstrained gaze estimation with L2CS-Net",
    "content": "Preprocessing and visualization.\nApplication!"
  },
  {
    "date": "2021-12-06T10:00:00.001Z",
    "data-tags": "literature",
    "image": "images/blog/saliency1/cover.PNG",
    "title": "Unlocking the Black Box with Saliency Maps",
    "content": "Unravel the mystery of AI decisions with saliency maps, a pivotal tool in making artificial intelligence transparent and understandable.",
    "page": "blog/saliency.html"
  },
  {
    "date": "",
    "data-tags": "literature code",
    "image": "images/placeholder/pic04.jpg",
    "title": "Return of heroes: HOTS Drafter",
    "content": "Visualization.\nOpenGraphAU."
  },
  {
    "date": "",
    "data-tags": "code",
    "image": "images/placeholder/pic01.jpg",
    "title": "Heart Rate Variability (HRV) preprocessing and visualization",
    "content": "This is the first sentence.\nThis is the second sentence."
  },
  {
    "date": "",
    "data-tags": "literature code",
    "image": "images/placeholder/pic03.jpg",
    "title": "Gaze benchmark databases",
    "content": "Visualization.\nInformation."
  },
  {
    "date": "",
    "data-tags": "literature code",
    "image": "images/placeholder/pic04.jpg",
    "title": "Action Units in action",
    "content": "Visualization.\nOpenGraphAU."
  }
]
