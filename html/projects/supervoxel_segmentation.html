<!DOCTYPE HTML>
<html>
	<head>
		<title>Adam Fodor portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
		<link rel="stylesheet" href="../../css/styles.css" />
		<noscript><div class="alert alert-warning" role="alert"><h2>Warning!</h2><p>This website requires JavaScript to function. Please enable JavaScript in your browser settings.</p></div></noscript>
	</head>

	<body class="is-preload">
		<header>
			<div id="menu-header">
				<nav>
					<ul>
						<li><a href="#menu">Menu</a></li>
					</ul>
				</nav>
			</div>

			<nav id="menu">
				<h2>
					Menu
					<span id="themeSwitch" class="theme-icon" aria-label="Toggle Theme"><i class="far fa-moon"></i></span>
				</h2>
				<ul>
					<li><a href="../../index.html">Home</a></li>
					<li><a href="../projects.html">Projects</a></li>
					<li><a href="../blog.html">Blog</a></li>
					<li><a href="../events.html">Events</a></li>
					<li><a href="../teaching.html">Teaching</a></li>
					<li><a href="../gallery.html">Gallery</a></li>
					<li><a href="../about.html">About</a></li>
				</ul>
			</nav>		
		</header>

		<div class="container">
			<div class="paper">
				<h1>Common Fate Based Episodic Segmentation by Combining Supervoxels with Deep Neural Networks</h1>
				<p>László Kopácsi, Áron Fóthi, Ádám Fodor, Ellák Somfai, András Lőrincz</p>
			</div>
			<img class="img-fluid rounded middle" src="../../images/projects/supervoxel_segmentation/segmentation.png" alt=""/>
			<div class="d-flex mt-4 mb-4">
				<a id="button_contact" target="_blank" href="../../pdf/2019_Fodor_Adam_IJCNN_SuperVoxel_OF.pdf" class="button mx-3">Paper</a>
				<a id="button_contact" target="_blank" href="https://github.com/lkopi/common-fate-segmentation" class="button primary mx-3">Code</a>
			</div>

			<div class="row">
				<div class="col"></div>
				<div class="col-6 abstract-container">
					<div class="abstract">
						<h2>Abstract</h2>
						<p>We estimated the contribution of different factors in
							segmentation tasks by means of deep neural networks. Results
							indicated that texture and optical flow have similar power, but
							they seem not to add up. In turn, we decided to study the
							‘Common Fate Principle’ of the 100 years gestaltism suggesting
							that elements that move together belong together. We developed
							a simple, fast, and efficient episodic segmentation method that
							– to some extent – resembles the ‘how system’ of the visual
							processing: we dropped every piece of information except motion,
							and started from pure optical flow estimations on 2D videos.
							For the sake of segmentation, we used a parallel and fast
							hierarchical supervoxel algorithm. We studied (i) grid topology
							in space and time, (ii) 2D grid in space and topology dictated
							by the optical flow in time, and (iii) added deep network based
							depth estimation from 2D images. We measure performances on
							episodic foreground-background segmentation task of the Davis
							benchmark videos. Results are competitive to state-of-the-art
							segmentation techniques.</p>
					</div>
				</div>
				<div class="col"></div>
			</div>

			<h2>Contribution</h2>
			<ul>
				<li>We introduce a novel, but simple method for episodic segmentation motivated by Gestalt principles with competitive performance on a benchmark problem. The method changes the topology of space according to motion.</li>
				<li>We show the application of deep networks as adaptable sensors for optical flow and depth estimation and presenting their effects.</li>
				<li>We also point to additional information pieces that should improve the performance of the method.</li>
			</ul>

			<h2>Proposed method</h2>
				<p>We investigated the Common Fate Principle from gestaltism - which proposes that elements moving together belong together - 
					and developed an episodic segmentation method based on motion, optical flow, and hierarchical supervoxel algorithm.</p>
				<p>We used the novel deep learning PWC-Net method
					for the estimation of the optical flow. This method exploits
					a pyramidal computation that regularizes the optical flow by
					diminishing the aperture problem through the pyramid based
					spatial context.</p>
				<p>For the sake of segmentation, we apply Boruvka’s algorithm,
					a highly parallel and hierarchical supervoxel method that
					can be seen as a special kind of spreading activation that finds
					the minimal spanning tree of a graph. In our case, the graph
					could be the grid on frames with vertices (pixels) connected
					with corresponding pixels of the previous and the next frame.
					Alternatively, pixels of the frames belonging to different time
					instants can be connected by means of the optical flow itself.
					We study both cases. We also add monocular depth estimation
					via a trained deep neural network.</p>
				<p>For a 2D image the vertices of the graph are the pixels, and
					the edges connect neighboring pixels in the pixel grid.
					In a sequence of video frames the pixels of the frames form
					a 3D structure and elements of the structure become voxels.
					A contiguous group of similar voxels, which has both spatial
					and temporal extent, is a supervoxel.</p>
				<p>We used two methods for computing supervoxels. 
					In the first case, the topology of the
					graph was defined by neighboring pixels within each frame
					and the ‘neighboring’ pixels in time was also connected if
					they had the same spatial position. In the other case, the edges
					connecting pixels within a frame are the same as above, but
					the edges connecting pixels in neighboring frames follow the
					optical flow. The weights of the connections were determined
					by considering the absolute values of the differences of the
					optical flow components. In some experiments we also added
					the differences of depth estimations to the weights.</p>

			<h2>Visualization</h2>
			<p>High quality examples for Common Fate Principle based segmentation. Middle row: case where occlusion spoils the
			result. Columns in order from left to right: RGB image, supervoxel masks on the 1st, 4th, 8th, 12th and 16th frames.</p>
			<img class="img-fluid rounded middle" src="../../images/projects/supervoxel_segmentation/examples.png" alt=""/>
			<p>We presented that optical flow based segmentation has
				strength by its own. We also found that optical flow based
				information may spoil texture based segmentation in both
				supervised and unsupervised settings, possibly due to the noise
				content of optical flow estimation as well as to occlusions.</p>

			<h2>BibTex</h2>
			<p>If you found our research helpful or influential please consider citing:</p>
			<pre><code class="bibtex">@INPROCEEDINGS{8851697,
   author = {Kopácsi, László and Fóthi, Áron and Fodor, Ádám and Somfai, Ellák and Lőrincz, András},
   booktitle = {2019 International Joint Conference on Neural Networks (IJCNN)}, 
   title = {Common Fate Based Episodic Segmentation by Combining Supervoxels with Deep Neural Networks}, 
   year = {2019},
   pages = {1-7},
   doi = {10.1109/IJCNN.2019.8851697}
}</code></pre>
		</div>

		<div class="d-flex mt-4 mb-4"><a id="button_contact" href="#" class="button mx-3">Details at the Top: Paper</a></div>
		<div id="footer-container"></div>

		<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js"></script>
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>	
		<script src="https://kit.fontawesome.com/a8f44bbdfa.js"></script>
		<script src="../../js/menu.js"></script>
		<script src="../../js/pre-load.js"></script>
		<script src="../../js/footer.loader.js"></script>
	</body>
</html>